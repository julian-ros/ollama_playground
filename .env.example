# Model Configuration Example
# Copy this file to .env and modify as needed

# Streamlit Frontend Chat Model
# Popular options: llama3.2, llama3.1, llama2, mistral, codellama
OLLAMA_CHAT_MODEL_STREAMLIT=llama3.2

# Embeddings API Chat Model (for document-enhanced responses)
# Should be a good general-purpose model
OLLAMA_CHAT_MODEL_EMBEDDINGS_API=llama3.2

# Embeddings Model (for document vectorization)
# Options: all-minilm, nomic-embed-text, mxbai-embed-large
OLLAMA_EMBEDDINGS_MODEL=all-minilm

# Data path for documents to process
EMBEDDINGS_DATA_PATH=/app/data